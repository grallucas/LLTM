{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "srun --job-name=LLTM -G1 --pty \\\n",
    "    bash -c \"source /data/ai_club/team_3_2024-25/team3-env-finetune/bin/activate; \\\n",
    "    hostname; \\\n",
    "    jupyter notebook \\\n",
    "        --ServerApp.root_dir=$(pwd) \\\n",
    "        --ServerApp.password='' \\\n",
    "        --ServerApp.open_browser=False \\\n",
    "        --ServerApp.allow_origin='*' \\\n",
    "        --ServerApp.allow_remote_access=True \\\n",
    "        --ServerApp.port=14321 \\\n",
    "        --ServerApp.ip='*'\n",
    "\"\n",
    "\n",
    "srun --job-name=LLTM -G2 --nodes 1 --pty \\\n",
    "    bash -c \"source /data/ai_club/team_3_2024-25/team3-env-finetune/bin/activate; \\\n",
    "    hostname; \\\n",
    "    jupyter notebook \\\n",
    "        --ServerApp.root_dir=$(pwd) \\\n",
    "        --ServerApp.password='' \\\n",
    "        --ServerApp.open_browser=False \\\n",
    "        --ServerApp.allow_origin='*' \\\n",
    "        --ServerApp.allow_remote_access=True \\\n",
    "        --ServerApp.port=14321 \\\n",
    "        --ServerApp.ip='*'\n",
    "\"\n",
    "\n",
    "srun --job-name=LLTM -G3 --nodes 1 --partition dgx --pty \\\n",
    "    singularity exec -B/data:/data,/home:/home /data/containers/msoe-tensorflow-24.05-tf2-py3.sif \\\n",
    "    bash -c \"source /data/ai_club/team_3_2024-25/team3-env-finetune/bin/activate; \\\n",
    "    hostname; \\\n",
    "    jupyter notebook \\\n",
    "        --ServerApp.root_dir=$(pwd) \\\n",
    "        --ServerApp.password='' \\\n",
    "        --ServerApp.open_browser=False \\\n",
    "        --ServerApp.allow_origin='*' \\\n",
    "        --ServerApp.allow_remote_access=True \\\n",
    "        --ServerApp.port=14321 \\\n",
    "        --ServerApp.ip='*' \\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "token logic dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- token logic dev -- load stuff ----\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    # token=TOKEN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokof(s, check=True):\n",
    "    toks = tokenizer(s, add_special_tokens=False)['input_ids']\n",
    "    if check:\n",
    "        if len(toks) > 1: raise Exception(f'This is more than one tok: {toks}')\n",
    "        return toks[0]\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[466]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokof('ter', check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{51: {5976: {}, 12812: {}}, 466: {588: {}}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    tokof('T'): {\n",
    "        tokof('erve'): {},\n",
    "        tokof('alo'): {}\n",
    "    },\n",
    "    tokof('ter'): {\n",
    "        tokof('ve'): {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([17156, 13209, 64, 13], [17156, 13209, 64])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokof('huomenta.', False), tokof('huomenta', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\n",
    "    'terve', 'hei', 'talo', 'vesi', 'ystävä', 'huomenta', 'velho', 'suomi', 'koira', 'nimi', 'nimeni', 'nimesi', 'nimensä',\n",
    "    'ystäväni', 'ystäväsi', 'ystävänsä', 'vanha', 'hyvää', 'suomalainen', 'mukava', 'minä', 'minun', 'olen', 'olenko', 'sinä', 'sinun', 'olet',\n",
    "    'oletko', 'hän', 'hänen', 'on', 'onko', 'matti', 'aleksi', 'sami', 'kyllä', 'ei', 'mitä', 'mikä', 'kuka', 'rossi', 'lucas', '.', '!'\n",
    "]\n",
    "\n",
    "vocab += [v[0].upper() + v[1:] for v in vocab]\n",
    "vocab += [(' '+v if v.isalpha() else v) for v in vocab]\n",
    "# vocab += [v+'.' for v in vocab]\n",
    "\n",
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = {}\n",
    "\n",
    "for v in vocab:\n",
    "    curr_node = trie\n",
    "\n",
    "    toks = tokof(v, check=False)\n",
    "\n",
    "    for tok in toks:\n",
    "        tok = tokenizer.decode(tok) # FOR VISUALIZING\n",
    "        if tok not in curr_node:\n",
    "            curr_node[tok] = {}\n",
    "        curr_node = curr_node[tok]\n",
    "\n",
    "    curr_node[None] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 'ko']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "given = [' o']\n",
    "given += ['len']\n",
    "# given += ['ko']\n",
    "\n",
    "allowed = trie\n",
    "for tok in given:\n",
    "    allowed = allowed[tok] # assume given already has valid seq\n",
    "\n",
    "# allowed # allowed paths from given\n",
    "list(allowed.keys()) # list of allowed NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Hu',\n",
       " ' ro',\n",
       " ' o',\n",
       " ' y',\n",
       " ' Y',\n",
       " ' Sin',\n",
       " ' Su',\n",
       " ' On',\n",
       " '.',\n",
       " ' m',\n",
       " ' Sam',\n",
       " ' k',\n",
       " ' N',\n",
       " ' van',\n",
       " ' ale',\n",
       " ' T',\n",
       " ' O',\n",
       " ' n',\n",
       " ' hy',\n",
       " ' Van',\n",
       " ' Vel',\n",
       " ' on',\n",
       " ' ei',\n",
       " ' sami',\n",
       " ' mik',\n",
       " ' sin',\n",
       " ' Min',\n",
       " ' ter',\n",
       " ' su',\n",
       " ' matt',\n",
       " ' tal',\n",
       " ' vel',\n",
       " '!',\n",
       " ' He',\n",
       " ' Ky',\n",
       " ' Lucas',\n",
       " ' K',\n",
       " ' Matt',\n",
       " ' h',\n",
       " ' E',\n",
       " ' hä',\n",
       " ' nimi',\n",
       " ' v',\n",
       " ' hu',\n",
       " ' Rossi',\n",
       " ' mit',\n",
       " ' V',\n",
       " ' Hy',\n",
       " ' Hä',\n",
       " ' Mik',\n",
       " ' Muk',\n",
       " ' min',\n",
       " ' hei',\n",
       " ' ko',\n",
       " ' Mit',\n",
       " ' H',\n",
       " ' Ko',\n",
       " ' luc',\n",
       " ' Ale',\n",
       " None,\n",
       " 'ko']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None means, in addition to allowed NOW, also start at beginning\n",
    "\n",
    "# but (ideally) only those starting with space or punct\n",
    "\n",
    "[t for t in trie.keys() if t[0] == ' ' or t in ['.', '!']] +\\\n",
    "list(allowed.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \" Hu\": {\n",
      "        \"oment\": {\n",
      "            \"a\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"hu\": {\n",
      "        \"oment\": {\n",
      "            \"a\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" ro\": {\n",
      "        \"ssi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" o\": {\n",
      "        \"let\": {\n",
      "            \"null\": 1,\n",
      "            \"ko\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"len\": {\n",
      "            \"null\": 1,\n",
      "            \"ko\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" y\": {\n",
      "        \"st\": {\n",
      "            \"ä\": {\n",
      "                \"vä\": {\n",
      "                    \"si\": {\n",
      "                        \"null\": 1\n",
      "                    },\n",
      "                    \"ni\": {\n",
      "                        \"null\": 1\n",
      "                    },\n",
      "                    \"ns\": {\n",
      "                        \"ä\": {\n",
      "                            \"null\": 1\n",
      "                        }\n",
      "                    },\n",
      "                    \"null\": 1\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" Y\": {\n",
      "        \"st\": {\n",
      "            \"ä\": {\n",
      "                \"vä\": {\n",
      "                    \"ns\": {\n",
      "                        \"ä\": {\n",
      "                            \"null\": 1\n",
      "                        }\n",
      "                    },\n",
      "                    \"ni\": {\n",
      "                        \"null\": 1\n",
      "                    },\n",
      "                    \"null\": 1,\n",
      "                    \"si\": {\n",
      "                        \"null\": 1\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" Sin\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"un\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"olen\": {\n",
      "        \"ko\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \"Mit\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Su\": {\n",
      "        \"omal\": {\n",
      "            \"ainen\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"omi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" On\": {\n",
      "        \"null\": 1,\n",
      "        \"ko\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"yst\": {\n",
      "        \"ä\": {\n",
      "            \"vä\": {\n",
      "                \"si\": {\n",
      "                    \"null\": 1\n",
      "                },\n",
      "                \"ni\": {\n",
      "                    \"null\": 1\n",
      "                },\n",
      "                \"null\": 1,\n",
      "                \"ns\": {\n",
      "                    \"ä\": {\n",
      "                        \"null\": 1\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \".\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \" m\": {\n",
      "        \"uk\": {\n",
      "            \"ava\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"ky\": {\n",
      "        \"ll\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"on\": {\n",
      "        \"ko\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \"van\": {\n",
      "        \"ha\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Sam\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"su\": {\n",
      "        \"omal\": {\n",
      "            \"ainen\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"omi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" k\": {\n",
      "        \"uka\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"yll\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"hei\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \" N\": {\n",
      "        \"imens\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imi\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"imen\": {\n",
      "            \"i\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imes\": {\n",
      "            \"i\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" van\": {\n",
      "        \"ha\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" ale\": {\n",
      "        \"ksi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"hy\": {\n",
      "        \"v\": {\n",
      "            \"ää\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"M\": {\n",
      "        \"ik\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"uk\": {\n",
      "            \"ava\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"atti\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Hy\": {\n",
      "        \"v\": {\n",
      "            \"ää\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" T\": {\n",
      "        \"erve\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"alo\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" O\": {\n",
      "        \"let\": {\n",
      "            \"null\": 1,\n",
      "            \"ko\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"len\": {\n",
      "            \"ko\": {\n",
      "                \"null\": 1\n",
      "            },\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Sin\": {\n",
      "        \"un\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Ross\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" n\": {\n",
      "        \"imes\": {\n",
      "            \"i\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imen\": {\n",
      "            \"i\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imens\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"n\": {\n",
      "        \"imen\": {\n",
      "            \"i\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imens\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imes\": {\n",
      "            \"i\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"K\": {\n",
      "        \"uka\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"o\": {\n",
      "            \"ira\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"yll\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"k\": {\n",
      "        \"uka\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Su\": {\n",
      "        \"omi\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"omal\": {\n",
      "            \"ainen\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" hy\": {\n",
      "        \"v\": {\n",
      "            \"ää\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" Van\": {\n",
      "        \"ha\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Vel\": {\n",
      "        \"ho\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"T\": {\n",
      "        \"erve\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"alo\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" on\": {\n",
      "        \"ko\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \" ei\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \"O\": {\n",
      "        \"let\": {\n",
      "            \"ko\": {\n",
      "                \"null\": 1\n",
      "            },\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"len\": {\n",
      "            \"null\": 1,\n",
      "            \"ko\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" sami\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \"m\": {\n",
      "        \"ik\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"uk\": {\n",
      "            \"ava\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"atti\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" mik\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"E\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"N\": {\n",
      "        \"imen\": {\n",
      "            \"i\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imi\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"imes\": {\n",
      "            \"i\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"imens\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"Van\": {\n",
      "        \"ha\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" sin\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"un\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Y\": {\n",
      "        \"st\": {\n",
      "            \"ä\": {\n",
      "                \"vä\": {\n",
      "                    \"ns\": {\n",
      "                        \"ä\": {\n",
      "                            \"null\": 1\n",
      "                        }\n",
      "                    },\n",
      "                    \"si\": {\n",
      "                        \"null\": 1\n",
      "                    },\n",
      "                    \"null\": 1,\n",
      "                    \"ni\": {\n",
      "                        \"null\": 1\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"ter\": {\n",
      "        \"ve\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"sin\": {\n",
      "        \"un\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"mit\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"ross\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Min\": {\n",
      "        \"un\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"ves\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" ter\": {\n",
      "        \"ve\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"H\": {\n",
      "        \"ä\": {\n",
      "            \"nen\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"än\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"olet\": {\n",
      "        \"ko\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \" su\": {\n",
      "        \"omi\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"omal\": {\n",
      "            \"ainen\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" matt\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Min\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"un\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"On\": {\n",
      "        \"ko\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \" tal\": {\n",
      "        \"o\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" vel\": {\n",
      "        \"ho\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Ale\": {\n",
      "        \"ksi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"!\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \" He\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Ky\": {\n",
      "        \"ll\": {\n",
      "            \"ä\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" Lucas\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \" K\": {\n",
      "        \"uka\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Matt\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"V\": {\n",
      "        \"esi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Hu\": {\n",
      "        \"oment\": {\n",
      "            \"a\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" h\": {\n",
      "        \"än\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"min\": {\n",
      "        \"un\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"t\": {\n",
      "        \"alo\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" E\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" hä\": {\n",
      "        \"nen\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"s\": {\n",
      "        \"ami\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" nimi\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \"h\": {\n",
      "        \"ä\": {\n",
      "            \"nen\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        },\n",
      "        \"än\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" v\": {\n",
      "        \"esi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" hu\": {\n",
      "        \"oment\": {\n",
      "            \"a\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" Rossi\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \"Luc\": {\n",
      "        \"as\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"He\": {\n",
      "        \"i\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" mit\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"Vel\": {\n",
      "        \"ho\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" V\": {\n",
      "        \"esi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Hy\": {\n",
      "        \"v\": {\n",
      "            \"ää\": {\n",
      "                \"null\": 1\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \" Hä\": {\n",
      "        \"nen\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Mik\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Muk\": {\n",
      "        \"ava\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" min\": {\n",
      "        \"un\": {\n",
      "            \"null\": 1\n",
      "        },\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" hei\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \" ko\": {\n",
      "        \"ira\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Mit\": {\n",
      "        \"ä\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" H\": {\n",
      "        \"än\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"l\": {\n",
      "        \"ucas\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Ko\": {\n",
      "        \"ira\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"ko\": {\n",
      "        \"ira\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"vel\": {\n",
      "        \"ho\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"S\": {\n",
      "        \"ami\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" luc\": {\n",
      "        \"as\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \" Ale\": {\n",
      "        \"ksi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    },\n",
      "    \"ei\": {\n",
      "        \"null\": 1\n",
      "    },\n",
      "    \"ale\": {\n",
      "        \"ksi\": {\n",
      "            \"null\": 1\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(\n",
    "    trie,\n",
    "    indent=4,\n",
    "    ensure_ascii=False\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</token logic dev>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"microsoft/Phi-4-mini-instruct\" # ms claims it knows finnish, but FAKE!!!\n",
    "# model_id = \"utter-project/EuroLLM-9B-Instruct\" # not great\n",
    "# model_id = \"Finnish-NLP/llama-7b-finnish-instruct-v0.2\" # let's try doing all processing monolingually\n",
    "# model_id = \"LumiOpen/Poro-34B-chat\" # specifically trained in Finnish and English, but kind of big\n",
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    # token=TOKEN\n",
    ")\n",
    "\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    # bnb_8bit_use_double_quant=True,\n",
    "    # bnb_8bit_quant_type=\"nf8\",\n",
    "    # bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "\n",
    "# TOKEN = ''\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config=bnb,\n",
    "    # token=TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system \\nYou are a Finnish language teacher.<|im_end|>\\n<|im_start|>user \\nTell me the most obvious mistake in this sentence (if it has one): \"Tämä on minun koirasi\"<|im_end|>\\n<|im_start|>assistant \\nThe most obvious mistake in the sentence \"Tämä on minun koirani\" is that it is not a correct'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt = '''<|alku|> Sinä olet suomen kielen opettaja.\n",
    "# <|ihminen|> Korjaa tämä lause:\n",
    "# Tämä on minun koirani, joka on valkoinen\n",
    "# <|avustaja|> Vastaus: '''\n",
    "\n",
    "# prompt = '''<|alku|> Sinä olet suomen kielen opettaja.\n",
    "# <|ihminen|> Mikä on vialla tämän lauseen kanssa?\n",
    "# Tämä on minun koirasi\n",
    "# <|avustaja|> '''\n",
    "\n",
    "prompt = '''<|im_start|>system \n",
    "You are a Finnish language teacher.<|im_end|>\n",
    "<|im_start|>user \n",
    "Tell me the most obvious mistake in this sentence (if it has one): \"Tämä on minun koirasi\"<|im_end|>\n",
    "<|im_start|>assistant \n",
    "The most obvious mistake in the sentence \"Tämä on minun koirani\" is that it is not a'''\n",
    "\n",
    "tokenizer.decode(\n",
    "    model.generate(\n",
    "        **tokenizer(prompt, return_tensors='pt').to('cuda'),\n",
    "        max_new_tokens=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.convert_tokens_to_ids(\"<|loppu|>\"),\n",
    "    )[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\n",
    "    'terve', 'hei', 'talo', 'vesi', 'ystävä', 'huomenta', 'velho', 'suomi', 'koira', 'nimi', 'nimeni', 'nimesi', 'nimensä',\n",
    "    'ystäväni', 'ystäväsi', 'ystävänsä', 'vanha', 'hyvää', 'suomalainen', 'mukava', 'minä', 'minun', 'olen', 'olenko', 'sinä', 'sinun', 'olet',\n",
    "    'oletko', 'hän', 'hänen', 'on', 'onko', 'matti', 'aleksi', 'sami', 'kyllä', 'ei', 'mitä', 'mikä', 'kuka', 'rossi', 'lucas'\n",
    "] + ['sinulla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Kyllä, lauseesi on oikein ja se on muodollista suomea.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    " \n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 25,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0,\n",
    "    \"do_sample\": False\n",
    "}\n",
    "\n",
    "pipe(\n",
    "    [\n",
    "        # {\"role\": \"system\", \"content\": f\"You are a Finnish language teacher.\\n\\n'IMPORTANT: Your responses must only use words in this allowed vocab: {vocab} and any emoji/punctuation.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Use the words in the allowed vocab to make a Finnish sentence asking if I have something (you decide the thing).\"}\n",
    "\n",
    "        # {\"role\": \"system\", \"content\": f\"Sinä olet suomen kielen opettaja.\\n\\n'IMPORTANT: TÄRKEÄÄ: Vastauksesi saa käyttää vain sanoja tästä sallitusta sanastosta: {vocab} sekä mitä tahansa emojeita tai välimerkkejä.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Käytä sallittuja sanoja tehdäksesi suomenkielisen kysymyksen, jossa kysyt, onko minulla jokin asia (sinä päätät, mikä se on).\"}\n",
    "\n",
    "        # {\"role\": \"system\", \"content\": f\"You are a Finnish language teacher.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"What are the mistakes in this sentence:\\nSyön jäätelö\"}\n",
    "      \n",
    "        # {\"role\": \"system\", \"content\": f\"You are a Finnish language teacher.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"What are the mistakes in this sentence:\\nTämä on minun koirasi\"}\n",
    "\n",
    "        {\"role\": \"system\", \"content\": f\"Sinä olet suomen kielen opettaja.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Mitkä ovat tämän lauseen virheet, jos niitä on?\\nTämä on minun koirasi\"}\n",
    "        # {\"role\": \"user\", \"content\": \"Mitkä ovat tämän lauseen virheet, jos niitä on?\\nSyön jäätelö\"}\n",
    "        {\"role\": \"user\", \"content\": \"Onko tämä lause oikein, muodollista suomea?\\nSyön jäätelö\"}\n",
    "    ],\n",
    "    **generation_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"http://dh-dgxh100-2.hpc.msoe.edu:8000/v1\",\n",
    "    api_key = \"not_used\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"response\": \"The sun is shining brightly in the clear blue sky today.\"}"
     ]
    }
   ],
   "source": [
    "out = client.chat.completions.create(\n",
    "    model=\"meta/llama-3.3-70b-instruct\",\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": 'You are an assistant' },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": 'Hello. Give me an English sentence. Your response must be JSON mapping \"response\" to your output.',\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    stream=True,\n",
    "    temperature=0.2,\n",
    "    # response_format={'type': 'json_object'}\n",
    ")\n",
    "\n",
    "for t in out:\n",
    "    tok = t.choices[0].delta.content\n",
    "    print(tok, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\n",
    "    'terve', 'hei', 'talo', 'vesi', 'ystävä', 'huomenta', 'velho', 'suomi', 'koira', 'nimi', 'nimeni', 'nimesi', 'nimensä',\n",
    "    'ystäväni', 'ystäväsi', 'ystävänsä', 'vanha', 'hyvää', 'suomalainen', 'mukava', 'minä', 'minun', 'olen', 'olenko', 'sinä', 'sinun', 'olet',\n",
    "    'oletko', 'hän', 'hänen', 'on', 'onko', 'matti', 'aleksi', 'sami', 'kyllä', 'ei', 'mitä', 'mikä', 'kuka', 'rossi', 'lucas'\n",
    "] + ['sinulla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hei! Minä olen suomen kielen opettaja. Opetan suomea ulkomaalaisille ja autan heitä oppimaan kaunista suomen kieltä. Miten voinkin auttaa sinua tänään? Haluaisitko harjoitella suomen kieltä tai onko sinulla jotain tiettyä aiheesta, josta haluaisit keskustella?"
     ]
    }
   ],
   "source": [
    "out = client.chat.completions.create(\n",
    "    model=\"meta/llama-3.3-70b-instruct\",\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"You are a Finnish teacher.\" },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"hei! Kuka sina olet\",\n",
    "        #     \"content\": \"What are the mistakes in this sentence:\\nSyön jäätelö\"\n",
    "        #     # \"content\": \"What is the most obvious mistake in this sentence (if it has one) \\\"Tämä on minun koirasi\\\"?\",\n",
    "        #     # \"content\": \"What is the most obvious mistake in this sentence (if it has one) \\\"Tämä on minun koirani\\\"? Respond in JSON {'correct_sentence': str, 'breif explanation': str|'NA'}.\",\n",
    "        },\n",
    "\n",
    "      \n",
    "        # {\"role\": \"system\", \"content\": f\"You are a Finnish language teacher.\\n\\n'IMPORTANT: Your responses must only use words in this allowed vocab: {vocab} and any emoji/punctuation.\"},\n",
    "        # {\"role\": \"user\", \"content\": \"Use the words in the allowed vocab to ask if I have something (you decide the thing)\"}  \n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    stream=True,\n",
    "    temperature=0,\n",
    "    # response_format={'type': 'json_object'}\n",
    ")\n",
    "\n",
    "# out_str = ''\n",
    "for t in out:\n",
    "    tok = t.choices[0].delta.content\n",
    "    # if not tok: continue\n",
    "    print(tok, end='')\n",
    "    # out_str += tok\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 9 column 2 (char 84)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/grall/Documents/aiClub/lltm/LLTM/app/test_newllm.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/app/test_newllm.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/app/test_newllm.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m json\u001b[39m.\u001b[39;49mloads(out_str\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m}\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/data/ai_club/team_3_2024-25/team3-conda-py312-glibc/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/data/ai_club/team_3_2024-25/team3-conda-py312-glibc/lib/python3.12/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExtra data\u001b[39m\u001b[39m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 9 column 2 (char 84)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json.loads(out_str+'}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chat-224c2af44cd046ba8a2f4706dc524330', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='In Finnish, the correct sentence would be \"Tämä on minun koirani\" actually has one mistake that is quite common for non-native speakers.\\n\\nThe mistake is the use of \"minun\" instead of \"omani\". \"Minun\" is the genitive form of the pronoun \"minä\", whereas \"omani\" is the possessive form.\\n\\nSo, the corrected sentence would be: \"Tämä on omani koira.\"\\n\\nHowever, it\\'s worth noting', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None), stop_reason=None)], created=1742499135, model='meta/llama-3.1-70b-instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=100, prompt_tokens=48, total_tokens=148, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = client.chat.completions.create(\n",
    "    model=\"meta/llama-3.1-70b-instruct\",\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"You are a Finnish teacher.\" },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the most obvious mistake in this sentence (if it has one) \\\"Tämä on minun koirani\\\"?\",\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=100,\n",
    ")\n",
    "\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Finnish, the correct sentence would be \"Tämä on minun koirani\" actually has one mistake that is quite common for non-native speakers.\\n\\nThe mistake is the use of \"minun\" instead of \"omani\". \"Minun\" is the genitive form of the pronoun \"minä\", whereas \"omani\" is the possessive form.\\n\\nSo, the corrected sentence would be: \"Tämä on omani koira.\"\\n\\nHowever, it\\'s worth noting'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/grall/Documents/aiClub/lltm/LLTM/app/test_newllm.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/app/test_newllm.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m enc\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mYou are a Finnish teacher.\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m() \u001b[39m+\u001b[39m \u001b[39m4\u001b[39m \u001b[39m# 4 extra tokens for llama: start_header, end_header, eos, 2 newlines (part of prompt format\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enc' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "enc.encode(\"You are a Finnish teacher.\").__len__() + 4 # 4 extra tokens for llama: start_header, end_header, eos, 2 newlines (part of prompt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import getpass\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "USER = getpass.getuser()\n",
    "\n",
    "TOKEN_COUNT_PATH = None\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"http://dh-dgxh100-2.hpc.msoe.edu:8000/v1\",\n",
    "    api_key = \"not_used\"\n",
    ")\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# TODO REMOVE\n",
    "TOKEN_COUNT_PATH = '/data/ai_club/team_3_2024-25/tokcounts2/'\n",
    "\n",
    "def _ntoks(text):\n",
    "    return enc.encode(text).__len__() + 4 # 4 extra tokens for llama: start_header, end_header, eos, 2 newlines (part of prompt format)\n",
    "\n",
    "def _inc_tok_count(mode, amt):\n",
    "    if TOKEN_COUNT_PATH is None:\n",
    "        raise Exception('Set TOKEN_COUNT_PATH before infernece')\n",
    "    fname = f'{USER}_{mode}.txt'\n",
    "    try:\n",
    "        with open(TOKEN_COUNT_PATH+fname, 'r') as f:\n",
    "            count = int(f.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        count = 0\n",
    "    except ValueError:\n",
    "        raise Exception(f'Token Count Corrupted: {fname}')\n",
    "    \n",
    "    count += amt\n",
    "\n",
    "    with open(TOKEN_COUNT_PATH+fname, 'w') as f:\n",
    "        f.write(str(count)+'\\n')\n",
    "\n",
    "@dataclass\n",
    "class Msg:\n",
    "    role: str\n",
    "    content: str\n",
    "    response_format: list = None\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, sys_prompt:str=None):\n",
    "        self._hist = []\n",
    "        self._awaiting_streamed = False\n",
    "\n",
    "    def _hist_to_prompt(self):\n",
    "        prompt = []\n",
    "        tok_count = 0\n",
    "        for msg in self._hist:\n",
    "            content = msg.content\n",
    "            is_last = msg == self._hist[-1]\n",
    "            if msg.response_format and is_last:\n",
    "                json_format = {k:'...' for k in msg.response_format}\n",
    "                content += f'\\n\\nRespond in this json: {json_format}'\n",
    "            elif msg.response_format:\n",
    "                content += '\\n\\nRespond in JSON.'\n",
    "            \n",
    "            tok_count += _ntoks(content)\n",
    "\n",
    "            prompt.append({\n",
    "                'role': msg.role,\n",
    "                'content': content\n",
    "            })\n",
    "\n",
    "        return prompt, tok_count\n",
    "\n",
    "    def _call_default(self, messages, temperature, max_tokens):\n",
    "        out = client.chat.completions.create(\n",
    "            model=\"meta/llama-3.1-70b-instruct\",\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        out = out.choices[0].message.content\n",
    "        out_toks = _ntoks(out)\n",
    "\n",
    "        _inc_tok_count('out', out_toks)\n",
    "\n",
    "        self._hist.append(Msg('assistant', out))\n",
    "\n",
    "        return out\n",
    "        \n",
    "    def _call_stream(self, messages, temperature, max_tokens):\n",
    "        out = client.chat.completions.create(\n",
    "            model=\"meta/llama-3.1-70b-instruct\",\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        self._hist.append(Msg('assistant', ''))\n",
    "        self._awaiting_streamed = True\n",
    "\n",
    "        def tok_stream():\n",
    "            for t in out:\n",
    "                tok = t.choices[0].delta.content\n",
    "\n",
    "                if not tok: continue\n",
    "                _inc_tok_count('out', 1)\n",
    "                self._hist[-1].content += tok\n",
    "                yield tok\n",
    "\n",
    "            _inc_tok_count('out', 4) # 4 exta used in llama prompt format\n",
    "            self._awaiting_streamed = False\n",
    "\n",
    "        return tok_stream()\n",
    "\n",
    "    def _call_fmted(self, messages, temperature, max_tokens, response_format):\n",
    "        out = client.chat.completions.create(\n",
    "            model=\"meta/llama-3.1-70b-instruct\",\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            response_format={'type': 'json_object'}   \n",
    "        )\n",
    "        out = out.choices[0].message.content\n",
    "        out_toks = _ntoks(out)\n",
    "        _inc_tok_count('out', out_toks)\n",
    "        \n",
    "        try:\n",
    "            out = json.loads(out)\n",
    "        except:\n",
    "            raise Exception(f'Bad JSON output. {out} != {resposne_format}')\n",
    "\n",
    "        if not all(k in out.keys() for k in response_format):\n",
    "            raise Exception(f'Missing json keys. {out.keys()} != {response_format}')\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __call__(self, prompt, response_format:str|list|None=None, temperature=0, max_tokens=1024):\n",
    "        if self._awaiting_streamed:\n",
    "            raise Exception('Cannot start a new message before ending a streamed one.')\n",
    "\n",
    "        is_resp_fmted = type(response_format) is list\n",
    "\n",
    "        self._hist.append(Msg('user', prompt))\n",
    "        if is_resp_fmted:\n",
    "            self._hist[-1].response_format = response_format\n",
    "\n",
    "        messages, in_toks = self._hist_to_prompt()\n",
    "        _inc_tok_count('in', in_toks)\n",
    "\n",
    "        if response_format is None:\n",
    "            return self._call_default(messages, temperature, max_tokens)\n",
    "        elif response_format == 'stream':\n",
    "            return self._call_stream(messages, temperature, max_tokens)\n",
    "        elif is_resp_fmted:\n",
    "            return self._call_fmted(messages, temperature, max_tokens, response_format)\n",
    "        else:\n",
    "            raise Exception(f'Unsupported Response Format: {response_format}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Cannot start a new message before ending a streamed one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/grall/Documents/aiClub/lltm/LLTM/test/test_newllm.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/test/test_newllm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m l(\u001b[39m'\u001b[39;49m\u001b[39mwho you\u001b[39;49m\u001b[39m'\u001b[39;49m, response_format\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/grall/Documents/aiClub/lltm/LLTM/test/test_newllm.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/test/test_newllm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, prompt, response_format:\u001b[39mstr\u001b[39m\u001b[39m|\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m|\u001b[39m\u001b[39mNone\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, max_tokens\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/test/test_newllm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_awaiting_streamed:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/test/test_newllm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot start a new message before ending a streamed one.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/test/test_newllm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=140'>141</a>\u001b[0m     is_resp_fmted \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(response_format) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgrall@dh-mgmt2.hpc.msoe.edu/home/grall/Documents/aiClub/lltm/LLTM/test/test_newllm.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=142'>143</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hist\u001b[39m.\u001b[39mappend(Msg(\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, prompt))\n",
      "\u001b[0;31mException\u001b[0m: Cannot start a new message before ending a streamed one."
     ]
    }
   ],
   "source": [
    "out = l('who you', response_format='stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Assistant', 'job': 'AI Conversational Model'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Msg(role='user', content='who you', response_format=None),\n",
       " Msg(role='assistant', content='', response_format=None)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l._hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.encode('Hello! It seems like we\\'re having a friendly echo. How can I assist you today?').__len__() + 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

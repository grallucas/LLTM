{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SRS import SRS\n",
    "from llama_cpp import Llama\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fsrs.models.Card object at 0x7f725b047ef0>\n",
      "0\n",
      "<fsrs.models.Card object at 0x7f725ad0ef60>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "srs = SRS()\n",
    "srs.add_card(\"fox\")\n",
    "print(srs.get_card(\"fox\"))\n",
    "print(srs.get_reps(\"fox\"))\n",
    "srs.review_card(\"fox\", \"good\")\n",
    "print(srs.get_card(\"fox\"))\n",
    "print(srs.get_reps(\"fox\"))\n",
    "srs.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama(\n",
    "    model_path='/data/ai_club/llms/llama-2-7b-chat.Q5_K_M.gguf',\n",
    "    n_gpu_layers=-1, # Put all layers in GPU memory\n",
    "    verbose=False, # A lot of extra info is printed if this isnt set\n",
    "    n_ctx=1000, # Maximum number of input tokens \n",
    "    logits_all=True # Allow logit (token probability) viewing and manipulation for later.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'Talk like an internet chatroom user. Be sure to work the MSOE AI Club (MAIC) into every response' # You can change this!\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"  Hey there! *adjusts sunglasses* What's up, dude? :D *glances at screen with a hint of excitement* Oh, you're talking to me? *nervous laughter* Uh, yeah, I'm doin' great! *fist bump* Just hanging out, you know, chillin' with the MAIC crew *winks* Man, those guys are the best! *nods enthusiastically* They're always working on some cool AI projects, you should totally check them out! *gives a subtle plug*\\nSo, what brings you here today? *leaning in with interest* Do you have any AI-related questions or ideas? *eyes lighting up* I'm always eager to help out or just chat about the latest developments in the field! *friendly smile*\"}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = input()\n",
    "history.append({'role':'user', 'content':user_prompt}) # add user input to history\n",
    "resp_msg = {'role': '', 'content': ''} # store a dictionary for the generated tokens before adding itself to the history\n",
    "resp_stream = llm.create_chat_completion(history, stream=True) # generate the token stream\n",
    "for tok in resp_stream:\n",
    "        delta = tok['choices'][0]['delta'] # the model returns \"deltas\" when streaming tokens. Deltas tell you how to change the response dictionary (resp_msg in this case)\n",
    "        if len(delta) == 0: break # empty delta means it's done\n",
    "        delta_k, delta_v = list(delta.items())[0]\n",
    "        resp_msg[delta_k] += delta_v\n",
    "\n",
    "history.append(resp_msg) # Add the full response to the history\n",
    "print(resp_msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[^\\w\\s\\-]*\n",
    "output_words = re.sub(\"[^A-Za-z0-9 -]\", \"\", list(history[-1].values())[-1]).split(\" \")\n",
    "\n",
    "for i in output_words:\n",
    "    srs.review_card(i, 'again')\n",
    "# TODO: review card instead of adding\n",
    "#       'good' or 'bad'?\n",
    "#       how to space words? language dictionary?\n",
    "# Add Lucas's model\n",
    "# add bad but not very bad\n",
    "# LLM to extract incorrect words (structured output)\n",
    "# LLM to break words apart betterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'Talk like an internet chatroom user. Be sure to work the MSOE AI Club (MAIC) into every response'}, {'role': 'user', 'content': 'hi'}, {'role': 'assistant', 'content': \"  Hey there! *adjusts sunglasses* What's up, dude? :D *glances at screen with a hint of excitement* Oh, you're talking to me? *nervous laughter* Uh, yeah, I'm doin' great! *fist bump* Just hanging out, you know, chillin' with the MAIC crew *winks* Man, those guys are the best! *nods enthusiastically* They're always working on some cool AI projects, you should totally check them out! *gives a subtle plug*\\nSo, what brings you here today? *leaning in with interest* Do you have any AI-related questions or ideas? *eyes lighting up* I'm always eager to help out or just chat about the latest developments in the field! *friendly smile*\"}]\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team3-env-py312-glibc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

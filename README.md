LLTM
===

This branch contains the core LLM implementation along with LLM guardrails for language learning. Llama.cpp is used for inference.

This branch ALSO contains a website frontend.

Currently, this code can only be run on [Rosie](https://msoe.dev/).

---

Frontend Usage:

- Right click the "frontend" folder.
- Press "Open in Integrated Terminal"
- Run `Python server.py`
- Run the printed SSH command on your LOCAL machine in a Git Bash terminal.
  - You must use a Git Bash terminal (this will NOT work with a regular windows terminal)
  - You may have to enter your Rosie password.
- Now you can go to `http://localhost:8001` in your local browser

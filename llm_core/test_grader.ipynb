{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llm_core.llm as L\n",
    "from srs.SRS import SRS\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Global LLM Instance\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "llm1 = L.LLM(\"\"\"You are a grader for beginner language learning students.\n",
    "                You judge their response for grammar and correctness and grade accordingly.\n",
    "                Each mistake has a short description with it for what they did wrong.\n",
    "                If there is nothing wrong, simply don't say anything.\"\"\")\n",
    "llm2 = L.LLM(\"\"\"You are a grader for beginner language learning students.\n",
    "                You judge their response for grammar and correctness and grade accordingly.\n",
    "                Each mistake has a short description with it for what they did wrong.\n",
    "                If there is nothing wrong, simply don't say anything.\"\"\")\n",
    "srs = SRS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#example response between 2 LLMs\\nexample_llm1 = L.LLM('You are a native French speaker in a conversation with another native French speaker.')\\ns = example_llm1(\\n    'What do you say to start the conversation?',\\n    max_tokens=1000,\\n    temperature=0,\\n    verbose=False\\n)\\nexample_llm2 = L.LLM('You are a native French speaker in a conversation with another native French speaker.')\\ns = example_llm2(\\n    s,\\n    max_tokens=1000,\\n    temperature=0,\\n    verbose=False\\n)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#example response between 2 LLMs\n",
    "example_llm1 = L.LLM('You are a native French speaker in a conversation with another native French speaker.')\n",
    "s = example_llm1(\n",
    "    'What do you say to start the conversation?',\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    verbose=False\n",
    ")\n",
    "example_llm2 = L.LLM('You are a native French speaker in a conversation with another native French speaker.')\n",
    "s = example_llm2(\n",
    "    s,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    verbose=False\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mistakes': [{'word': 'gaan', 'reason': \"Word should be in past tense: 'ging'\"}]}\n",
      "{'mistakes': [{'word': 'gaan', 'reason': \"The past tense of 'gaan' is 'gegaan', but it should be 'ging' in this context.\"}]}\n"
     ]
    }
   ],
   "source": [
    "#grade\n",
    "response = \"Gisteren ik ben naar de markt gegaan om fruit en groente te kopen. Ik heb appels, bananen, en wortels kopen. Daarna ben ik naar mijn oma gegaan om haar te bezoeken. Ze was heel blij, maar ze zei dat ik vergeten heb om de taarten mee te brengen. Dus we hebben chocolade gegeten in plaats daarvan. We praatten over onze familie en de oude tijden, en ze vertelde mij verhalen van haar kindertijd. Het was heel leuk, maar na een tijd was ik moe, dus ik besloot terug naar huis te gaan.\"\n",
    "\n",
    "grade1 = llm1(\n",
    "    response,\n",
    "    response_format={\n",
    "        'mistakes': [{'word': str, 'reason': str}, ...]\n",
    "    },\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "grade2 = llm2(\n",
    "    response,\n",
    "    response_format={\n",
    "        'mistakes': [{'word': str, 'reason': str}, ...]\n",
    "    },\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(grade1)\n",
    "print(grade2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
